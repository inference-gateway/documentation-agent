# Documentation Agent Configurations 
CONTEXT7_API_KEY=

# A2A Configuration

# Server Configuration
A2A_PORT=8080
A2A_DEBUG=false
A2A_AGENT_URL=http://localhost:8080
A2A_STREAMING_STATUS_UPDATE_INTERVAL=1s

# Agent Metadata
A2A_AGENT_CARD_FILE_PATH=.well-known/agent.json

# LLM Client Configuration
A2A_AGENT_CLIENT_PROVIDER=
A2A_AGENT_CLIENT_MODEL=
A2A_AGENT_CLIENT_MAX_TOKENS=4096
A2A_AGENT_CLIENT_TEMPERATURE=0.7
A2A_AGENT_CLIENT_SYSTEM_PROMPT=""

# LLM Provider Settings (set the appropriate one based on your provider)
A2A_AGENT_CLIENT_API_KEY=your-api-key-here
# A2A_AGENT_CLIENT_BASE_URL=https://api.openai.com/v1  # Optional: Custom endpoint

# Client Configuration
A2A_AGENT_CLIENT_TIMEOUT=30s
A2A_AGENT_CLIENT_MAX_RETRIES=3
A2A_AGENT_CLIENT_MAX_CHAT_COMPLETION_ITERATIONS=10

# Capabilities
A2A_CAPABILITIES_STREAMING=true
A2A_CAPABILITIES_PUSH_NOTIFICATIONS=false
A2A_CAPABILITIES_STATE_TRANSITION_HISTORY=true

# Task Management
A2A_TASK_RETENTION_MAX_COMPLETED_TASKS=100
A2A_TASK_RETENTION_MAX_FAILED_TASKS=50
A2A_TASK_RETENTION_CLEANUP_INTERVAL=5m

# Storage Configuration (optional)
A2A_QUEUE_PROVIDER=memory
# A2A_QUEUE_URL=redis://localhost:6379  # Required when using Redis
A2A_QUEUE_MAX_SIZE=100
A2A_QUEUE_CLEANUP_INTERVAL=30s

# Authentication (optional - OIDC)
A2A_AUTH_ENABLE=false
